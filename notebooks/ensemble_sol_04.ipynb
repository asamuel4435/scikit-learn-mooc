{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2570b8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (119937671.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mThe aim of the exercise is to get familiar with the histogram\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“ƒ Solution for Exercise M6.04\n",
    "\n",
    "The aim of the exercise is to get familiar with the histogram\n",
    "gradient-boosting in scikit-learn. Besides, we will use this model within a\n",
    "cross-validation framework in order to inspect internal parameters found via\n",
    "grid-search.\n",
    "\n",
    "We will use the California housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8924b174",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "fetch_california_housing with as_frame=True requires pandas.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\scikit-learn-mooc\\.venv\\Lib\\site-packages\\sklearn\\utils\\_optional_dependencies.py:42\u001b[39m, in \u001b[36mcheck_pandas_support\u001b[39m\u001b[34m(caller_name)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fetch_california_housing\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m data, target = \u001b[43mfetch_california_housing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_X_y\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_frame\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m target *= \u001b[32m100\u001b[39m  \u001b[38;5;66;03m# rescale the target in k$\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\scikit-learn-mooc\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\scikit-learn-mooc\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_california_housing.py:232\u001b[39m, in \u001b[36mfetch_california_housing\u001b[39m\u001b[34m(data_home, download_if_missing, return_X_y, as_frame, n_retries, delay)\u001b[39m\n\u001b[32m    228\u001b[39m target_names = [\n\u001b[32m    229\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMedHouseVal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    230\u001b[39m ]\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m as_frame:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     frame, X, y = \u001b[43m_convert_data_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfetch_california_housing\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_X_y:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\scikit-learn-mooc\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_base.py:116\u001b[39m, in \u001b[36m_convert_data_dataframe\u001b[39m\u001b[34m(caller_name, data, target, feature_names, target_names, sparse_data)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_data_dataframe\u001b[39m(\n\u001b[32m    114\u001b[39m     caller_name, data, target, feature_names, target_names, sparse_data=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    115\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     pd = \u001b[43mcheck_pandas_support\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m with as_frame=True\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sparse_data:\n\u001b[32m    118\u001b[39m         data_df = pd.DataFrame(data, columns=feature_names, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\scikit-learn-mooc\\.venv\\Lib\\site-packages\\sklearn\\utils\\_optional_dependencies.py:46\u001b[39m, in \u001b[36mcheck_pandas_support\u001b[39m\u001b[34m(caller_name)\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m requires pandas.\u001b[39m\u001b[33m\"\u001b[39m.format(caller_name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: fetch_california_housing with as_frame=True requires pandas."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e385885c",
   "metadata": {},
   "source": [
    "First, create a histogram gradient boosting regressor. You can set the trees\n",
    "number to be large, and configure the model to use early-stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "hist_gbdt = HistGradientBoostingRegressor(\n",
    "    max_iter=1000, early_stopping=True, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731fb73",
   "metadata": {},
   "source": [
    "We will use a grid-search to find some optimal parameter for this model. In\n",
    "this grid-search, you should search for the following parameters:\n",
    "\n",
    "* `max_depth: [3, 8]`;\n",
    "* `max_leaf_nodes: [15, 31]`;\n",
    "* `learning_rate: [0.1, 1]`.\n",
    "\n",
    "Feel free to explore the space with additional values. Create the grid-search\n",
    "providing the previous gradient boosting instance as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b498288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": [3, 8],\n",
    "    \"max_leaf_nodes\": [15, 31],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(hist_gbdt, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cce029",
   "metadata": {},
   "source": [
    "Finally, we will run our experiment through cross-validation. In this regard,\n",
    "define a 5-fold cross-validation. Besides, be sure to shuffle the data.\n",
    "Subsequently, use the function `sklearn.model_selection.cross_validate` to run\n",
    "the cross-validation. You should also set `return_estimator=True`, so that we\n",
    "can investigate the inner model trained via cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "results = cross_validate(\n",
    "    search,\n",
    "    data,\n",
    "    target,\n",
    "    cv=cv,\n",
    "    return_estimator=True,\n",
    "    # n_jobs=2  # Uncomment this if you run locally\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc5e52",
   "metadata": {},
   "source": [
    "Now that we got the cross-validation results, print out the mean and standard\n",
    "deviation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bca23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "print(\n",
    "    \"R2 score with cross-validation:\\n\"\n",
    "    f\"{results['test_score'].mean():.3f} Â± \"\n",
    "    f\"{results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971d790",
   "metadata": {},
   "source": [
    "Then inspect the `estimator` entry of the results and check the best\n",
    "parameters values. Besides, check the number of trees used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "for estimator in results[\"estimator\"]:\n",
    "    print(estimator.best_params_)\n",
    "    print(f\"# trees: {estimator.best_estimator_.n_iter_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e2c38",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "We observe that the parameters are varying. We can get the intuition that\n",
    "results of the inner CV are very close for certain set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6b198",
   "metadata": {},
   "source": [
    "Inspect the results of the inner CV for each estimator of the outer CV.\n",
    "Aggregate the mean test score for each parameter combination and make a box\n",
    "plot of these scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560128ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import pandas as pd\n",
    "\n",
    "index_columns = [f\"param_{name}\" for name in params.keys()]\n",
    "columns = index_columns + [\"mean_test_score\"]\n",
    "\n",
    "inner_cv_results = []\n",
    "for cv_idx, estimator in enumerate(results[\"estimator\"]):\n",
    "    search_cv_results = pd.DataFrame(estimator.cv_results_)\n",
    "    search_cv_results = search_cv_results[columns].set_index(index_columns)\n",
    "    search_cv_results = search_cv_results.rename(\n",
    "        columns={\"mean_test_score\": f\"CV {cv_idx}\"}\n",
    "    )\n",
    "    inner_cv_results.append(search_cv_results)\n",
    "inner_cv_results = pd.concat(inner_cv_results, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf1151",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color = {\"whiskers\": \"black\", \"medians\": \"black\", \"caps\": \"black\"}\n",
    "inner_cv_results.plot.box(vert=False, color=color)\n",
    "plt.xlabel(\"R2 score\")\n",
    "plt.ylabel(\"Parameters\")\n",
    "_ = plt.title(\n",
    "    \"Inner CV results with parameters\\n\"\n",
    "    \"(max_depth, max_leaf_nodes, learning_rate)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43182126",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "We see that the first 4 ranked set of parameters are very close. We could\n",
    "select any of these 4 combinations. It coincides with the results we observe\n",
    "when inspecting the best parameters of the outer CV."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
